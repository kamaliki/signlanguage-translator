{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b329d0c",
   "metadata": {},
   "source": [
    "## Import various libraries to be used in creating a dataset\n",
    "1. GLOB library the glob module is used to retrieve files/pathnames matching a specified pattern\n",
    "2. OS library provides functions for interacting with the operating system\n",
    "3. cv2 module designed to solve computer vision problems\n",
    "4. mediapipe module offers open source cross-platform, customizable ML solutions for live and streaming media\n",
    "5. matplotlib a cross-platform, data visualization and graphical plotting library\n",
    "6. numpy module a library consisting of multidimensional array objects and a collection of routines for processing those arrays\n",
    "7. tqdm allows you to output a smart progress bar by wrapping around any iterable. A tqdm progress bar not only shows you how much time has elapsed, but also shows the estimated time remaining for the iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'path_to_the_images_dataset'\n",
    "\n",
    "img_list = glob(os.path.join(base_path, 'train', '*.jpg'))\n",
    "\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53683777",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES = (img_list)\n",
    "#print(IMAGE_FILES)\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    print(results)\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      print('hand_landmarks:', hand_landmarks)\n",
    "      print(\n",
    "          f'Index finger tip coordinates: (',\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "      )\n",
    "      mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite(\n",
    "        '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "    # Draw hand world landmarks.\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      mp_drawing.plot_landmarks(\n",
    "        hand_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    static_image_mode=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = img_list[3]\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = hands.process(img)\n",
    "\n",
    "data = None\n",
    "\n",
    "if result.multi_hand_landmarks is not None:\n",
    "    for res in result.multi_hand_landmarks:\n",
    "        joint = np.zeros((21, 3))\n",
    "        for j, lm in enumerate(res.landmark):\n",
    "            joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "        # Compute angles between joints\n",
    "        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # Parent joint\n",
    "        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # Child joint\n",
    "        v = v2 - v1 # [20,3]\n",
    "        # Normalize v\n",
    "        v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Get angle using arcos of dot product\n",
    "        angle = np.arccos(np.einsum('nt,nt->n',\n",
    "            v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "            v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "        angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "        data = np.array([angle], dtype=np.float32)\n",
    "        \n",
    "        print(data)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "else:\n",
    "    print('Detection failed!')\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(os.path.basename(img_path)[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "    'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "    'W', 'X', 'Y', 'Z'\n",
    "]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for img_path in tqdm(img_list):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "\n",
    "    data = None\n",
    "    label = None\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 3))\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # Child joint\n",
    "            v = v2 - v1 # [20,3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "\n",
    "            label = os.path.basename(img_path)[0]\n",
    "            label_id = classes.index(label)\n",
    "            \n",
    "            data = np.append(data, label_id)\n",
    "            \n",
    "            data_list.append(data)\n",
    "            \n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a3ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('train.csv', data_list, delimiter=',')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
